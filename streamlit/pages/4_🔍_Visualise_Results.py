""" 
Streamlit page for visualising the results of evaluations in the 
AutoEval app.
    
Functionality:
- Visualize evaluation results using interactive plots.
- Filter data based on various parameters.
- Display specific details for selected runs.
"""

import json

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from dotenv import load_dotenv
import streamlit as st

from dataeditor import standardize_key_stage, standardize_subject
from utils import (
    clear_all_caches,
    json_to_html,
    execute_single_query,
    get_light_experiment_data,
    get_full_experiment_data
)

load_dotenv()


def fetch_and_preprocess_light_data():
    """
    Fetches and pre-process light experiment data.

    This function retrieves light experiment data and performs the
    following preprocessing steps:

    - Replaces parentheses in the 'experiment_name' column with square
        brackets.
    - Converts 'run_date' column to a string format (YYYY-MM-DD).
    - Creates a new column 'experiment_with_date' combining
        'experiment_name', 'run_date', and 'teacher_name'.

    Returns:
        pandas.DataFrame: A DataFrame containing the preprocessed light
            experiment data.
    """
    light_data = get_light_experiment_data()
    light_data['experiment_name'] = (
        light_data['experiment_name']
        .str.replace('(', '[', regex=False)
        .str.replace(')', ']', regex=False)
    )
    light_data['run_date'] = (
        pd.to_datetime(light_data['run_date']).dt.strftime('%Y-%m-%d')
    )

    light_data['experiment_with_date'] = light_data.apply(
        lambda x: (
            f"{x['experiment_name']} ({x['run_date']}) ({x['teacher_name']})"
        ),
        axis=1
    )
    return light_data


def fetch_and_preprocess_full_data(selected_experiment_id):
    """
    Fetches and pre-process full experiment data.

    This function retrieves full experiment data for a given experiment
    ID and performs the following preprocessing steps:

    - Standardizes the 'key_stage_slug' and 'subject_slug' columns.
    - Sorts the data by 'run_date' in descending order.
    - Converts 'run_date' column to a string format (YYYY-MM-DD).

    Args:
        selected_experiment_id (int): The ID of the selected experiment.

    Returns:
        pandas.DataFrame: A DataFrame containing the preprocessed full
            experiment data.

    """
    data = get_full_experiment_data(selected_experiment_id)
    data['key_stage_slug'] = data['key_stage_slug'].apply(standardize_key_stage)
    data['subject_slug'] = data['subject_slug'].apply(standardize_subject)
    data = data.sort_values(by='run_date', ascending=False)
    data['run_date'] = pd.to_datetime(data['run_date']).dt.strftime('%Y-%m-%d')
    return data


def apply_filters(data):
    """
    Apply filters to the experiment data based on user selections.

    This function provides multiple selection options for teachers,
    prompts, and samples to filter the experiment data. If no filters
    are applied, it displays all the data.

    Args:
        data (pandas.DataFrame): The experiment data to be filtered.

    Returns:
        pandas.DataFrame: The filtered experiment data.
    """
    selected_teachers = st.multiselect(
        'Select Teacher',
        options=data['teacher_name'].unique(),
        help="Select one or more teachers to filter the experiments."
    )
    selected_prompts = st.multiselect(
        'Select Prompt',
        options=data['prompt_title'].unique(),
        help="Select one or more prompts to filter the experiments."
    )
    selected_samples = st.multiselect(
        'Select Sample',
        options=data['sample_title'].unique(),
        help="Select one or more samples to filter the experiments."
    )
    if selected_teachers:
        data = data[data['teacher_name'].isin(selected_teachers)]
    if selected_prompts:
        data = data[data['prompt_title'].isin(selected_prompts)]
    if selected_samples:
        data = data[data['sample_title'].isin(selected_samples)]

    if not selected_teachers and not selected_prompts and not selected_samples:
        st.write("No filters applied. Showing all data.")

    return data


def display_pie_chart(data, group_by_column, title, column):
    """
    Display a pie chart for the given data grouped by a specified
    column.

    This function groups the data by the specified column, calculates
    the unique count of 'lesson_plan_id', and displays a pie chart using
    Plotly.

    Args:
        data (pandas.DataFrame): The data to be visualized.
        group_by_column (str): The column to group the data by.
        title (str): The title of the pie chart.
        column (streamlit.DeltaGenerator): The Streamlit column object
            to display the chart in.

    Returns:
        None
    """
    grouped_data = (
        data.groupby(group_by_column)
        ['lesson_plan_id'].nunique().reset_index()
    )
    grouped_data.columns = [group_by_column, 'count_of_lesson_plans']
    if not grouped_data.empty:
        fig = px.pie(
            grouped_data,
            values='count_of_lesson_plans',
            names=group_by_column,
            title=title
        )
        fig.update_layout(width=350, height=350, showlegend=False)
        fig.update_traces(
            textinfo='label',
            hoverinfo='percent+value',
            hovertemplate='%{label}: %{value} (<b>%{percent}</b>)'
        )
        column.plotly_chart(fig)


# Set page configuration
st.set_page_config(page_title="Visualise Results", page_icon="üîç")
st.title("üîç Visualise Results")

# Sidebar button to clear cache
if st.sidebar.button('Clear Cache'):
    clear_all_caches()
    st.sidebar.success('Cache cleared!')

# Fetch light data
light_data = fetch_and_preprocess_light_data()
experiment_description_options = (
    ['Select'] + light_data['experiment_with_date'].unique().tolist()
)

experiment = st.selectbox(
    'Select Experiment',
    experiment_description_options,
    help=(
        "Select an experiment to view more options."
        "(Run Date is in YYYY-MM-DD format)"
    )
)

# Extract the selected experiment_id
selected_experiment_id = None
if experiment != 'Select':
    selected_experiment_name = experiment.split(" (")[0]
    selected_experiment_id = light_data[
        light_data['experiment_name'] == selected_experiment_name
    ]['experiment_id'].iloc[0]
    result_id_input =""

if selected_experiment_id:
    # Fetch full data
    data = fetch_and_preprocess_full_data(selected_experiment_id)

    # Filter data
    if st.checkbox('Filter Experiment Data'):
        data = apply_filters(data)

    exp_data = data

    if experiment != 'Select':
        key_stage_options = exp_data['key_stage_slug'].unique().tolist()
        subject_options = exp_data['subject_slug'].unique().tolist()
        prompt_output_format_options = (
            exp_data['prompt_output_format'].unique().tolist()
        )

        st.write("Please select the filters to view the insights.")
        with st.expander("Key Stage and Subject Filters"):
            key_stage = st.multiselect(
                'Select Key Stage',
                key_stage_options,
                default=key_stage_options[:]
            )
            subject = st.multiselect(
                'Select Subject',
                subject_options,
                default=subject_options[:]
            )

        st.write("Please select the outcome option to view the insights.")
        output_selection = st.selectbox(
            'Select Outcome Type', prompt_output_format_options
        )

        if output_selection:
            sample_title_options = exp_data['sample_title'].unique().tolist()
            selected_samples = st.multiselect(
                'Select Sample Title',
                sample_title_options,
                default=sample_title_options
            )

            exp_data = exp_data[
                (exp_data['sample_title'].isin(selected_samples)) &
                (exp_data['prompt_output_format'] == output_selection)
            ]

            prompt_title_options = exp_data['prompt_title'].unique().tolist()
            result_status_options = exp_data['result_status'].unique().tolist()
            result_status = st.multiselect(
                'Select Experiment Status',
                result_status_options,
                default='SUCCESS'
            )

            exp_data = exp_data[
                (exp_data['result_status'].isin(result_status))
            ]
            prompt_title = st.multiselect(
                'Select Prompt Title',
                prompt_title_options,
                default=prompt_title_options[:]
            )

            exp_data['result'] = (
                pd.to_numeric(exp_data['result'], errors='coerce')
            )
            exp_data.loc[
                exp_data['prompt_output_format'] == 'Boolean', 'result'
            ] = exp_data['result'].map({0: 'False', 1: 'True'})

            mask = (exp_data['prompt_output_format'] != 'Boolean') & (
                exp_data['result'].apply(
                    lambda x: isinstance(x, str)
                    or not isinstance(x, (int, float))
                )
            )
            exp_data.loc[mask, 'result'] = (
                exp_data.loc[mask, 'result'].astype(float)
            )

            outcome_options = exp_data['result'].unique().tolist()
            if output_selection == 'Score':
                outcome_options = sorted(outcome_options)

            outcome = st.multiselect(
                'Filter by Result Outcome',
                outcome_options,
                default=outcome_options[:]
            )

            filtered_data = exp_data[
                (exp_data['key_stage_slug'].isin(key_stage))
                & (exp_data['subject_slug'].isin(subject))
                & (exp_data['result_status'].isin(result_status_options))
                & (exp_data['prompt_title'].isin(prompt_title))
                & (exp_data['result'].isin(outcome))
            ]

            filtered_data['result_numeric'] = (
                filtered_data['result']
                .map({"TRUE": 1, "FALSE": 0})
                .fillna(filtered_data['result'])
            )
            filtered_data['result_numeric'] = pd.to_numeric(
                filtered_data['result_numeric'],
                errors='coerce'
            )

            # Display metrics
            col1, col2, col3 = st.columns(3)
            col1.metric(
                "Number of Lesson Plans in Selection: ",
                filtered_data['lesson_plan_id'].nunique()
            )
            col2.metric("Evaluator Model", filtered_data['llm_model'].iloc[0])

            display_pie_chart(
                filtered_data,
                'key_stage_slug',
                'Lesson Plans by Key Stage',
                col1
            )
            display_pie_chart(
                filtered_data,
                'subject_slug',
                'Lesson Plans by Subject',
                col2
            )

            # Sidebar for justification lookup
            st.sidebar.header('Justification Lookup')
            st.sidebar.write(
                "Please copy the result_id from the Data Viewer to "
                "view the justification."
            )
            result_id_input = st.sidebar.text_input('Enter Result ID')

            if result_id_input:
                result_data = filtered_data[
                    filtered_data['result_id'] == result_id_input
                ]
                if not result_data.empty:
                    lesson_plan_id = result_data['lesson_plan_id'].iloc[0]
                    lesson_plan_data = execute_single_query(
                        "SELECT json FROM lesson_plans WHERE id = %s",
                        (lesson_plan_id,),
                        return_dataframe=True
                    )

                    if not lesson_plan_data.empty:
                        lesson_plan_json = lesson_plan_data['json'].iloc[0]
                        lesson_plan_dict = json.loads(lesson_plan_json)
                        justification_text = (
                            result_data['justification'].iloc[0]
                        )
                        lesson_plan_parts = (
                            result_data['prompt_lp_params'].iloc[0]
                        )

                        st.sidebar.header(f'Lesson Plan ID: {lesson_plan_id}')
                        st.sidebar.header('Justification for Selected Run')
                        st.sidebar.write(
                            f"**Justification**: {justification_text}"
                        )
                        st.sidebar.header("**Relevant Lesson Parts**")
                        st.sidebar.write(f'{lesson_plan_parts}')

                        st.sidebar.header(
                            "**Relevant Lesson Plan Parts Extracted**:"
                        )
                        html_text = ""
                        for key, value in lesson_plan_dict.items():
                            if key in lesson_plan_parts:
                                if isinstance(value, (str, int, float)):
                                    html_text += (
                                        f"<p><strong>{key}</strong>: "
                                        f"{value}</p>"
                                    )
                                else:
                                    html_text += (
                                        f"<p><strong>{key}</strong>:</p>"
                                        f"{json_to_html(value, indent=1)}"
                                    )
                        st.sidebar.markdown(html_text, unsafe_allow_html=True)

                        st.sidebar.header('Relevant Lesson Plan')
                        lesson_plan_text = json_to_html(
                            lesson_plan_dict,
                            indent=0
                        )
                        st.sidebar.markdown(
                            lesson_plan_text, unsafe_allow_html=True
                        )

                    else:
                        st.sidebar.error('No data found for this Run ID')
                else:
                    st.sidebar.error('No data found for this Run ID')

            color_mapping = {
                "Gen-claude-3-opus-20240229-0.3": "lightgreen",
                "Gen-gemini-1.5-pro-1": "lightblue",
                "Gen-gpt-4-turbo-0.5": "pink",
                "Gen-gpt-4-turbo-0.7": "lightcoral",
                # Add more mappings as needed
            }

            # Result_data
            # Assuming the ideal score is 5
            if output_selection == 'Score':
                IDEAL_SCORE = 5
                # Calculate the percentage success for each result
                filtered_data['result_percent'] = (
                    (filtered_data['result_numeric'] / IDEAL_SCORE) * 100
                )

                # Ensure result_percent is within 0 to 100
                success_filtered_data = filtered_data[
                    (filtered_data['result_percent'] >= 0) &
                    (filtered_data['result_percent'] <= 100)
                ]

                # Calculate the average success rate for each prompt
                # title and sample title
                average_success_rate = success_filtered_data.groupby(
                    ['prompt_title', 'sample_title']
                )['result_percent'].mean().reset_index()

                # Calculate the overall average success rate for each
                # prompt title
                overall_success_rate = (
                    success_filtered_data.groupby('prompt_title')
                    ['result_percent'].mean().reset_index()
                )

                # Display the diagnostics to ensure data is correct
                with st.expander("Success Rate Diagnostics"):
                    st.write(
                        "Diagnostics: After grouping and calculating "
                        "average success rate"
                    )
                    st.write(average_success_rate)

                # Creating a layered spider chart
                fig = go.Figure()

                unique_samples = average_success_rate['sample_title'].unique()
                num_samples = len(unique_samples)
                # Generate a list of colors using Plotly's color palette
                colors = px.colors.qualitative.Plotly[:num_samples]

                for i, sample in enumerate(unique_samples):
                    sample_data = average_success_rate[
                        average_success_rate['sample_title'] == sample
                    ]
                    categories = sample_data['prompt_title'].tolist()
                    values = sample_data['result_percent'].tolist()

                    # Append the first value to the end to close the
                    # circle in the spider chart
                    values += values[:1]
                    categories += categories[:1]

                    # Add trace for each sample with a different color
                    fig.add_trace(
                        go.Scatterpolar(
                            r=values,
                            theta=categories,
                            fill='toself',
                            name=sample,
                            # Assign color from the generated list
                            line=dict(color=colors[i % num_samples])
                        )
                    )

                # Add overall success rate as a dotted line plot
                overall_categories = (
                    overall_success_rate['prompt_title'].tolist()
                )
                overall_values = (
                    overall_success_rate['result_percent'].tolist()
                )

                # Append the first value to the end to close the circle
                # in the spider chart
                overall_values += overall_values[:1]
                overall_categories += overall_categories[:1]

                fig.add_trace(
                    go.Scatterpolar(
                        r=overall_values,
                        theta=overall_categories,
                        mode='lines',
                        line=dict(color='black', dash='dot'),
                        name='Overall Average'
                    )
                )

                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(visible=True,range=[0, 100])
                    ),
                    showlegend=True,
                    title=(
                        "Average Success Rate by Prompt Title "
                        "and Sample Title"
                    )
                )

                st.plotly_chart(fig)

                # Convert 'True' and 'False' strings to boolean values
                # in the 'result' column
                filtered_data['success'] = (
                    filtered_data['result'].map({'True': True, 'False': False})
                )

                # Calculate the count of successful results compared
                # to the total number of results per prompt title and
                # sample title
                count_of_results = (
                    filtered_data.groupby(['prompt_title', 'sample_title'])
                    ['success'].value_counts().unstack(fill_value=0)
                    .reset_index()
                )

                # Ensure both 'True' and 'False' columns exist
                if True not in count_of_results.columns:
                    count_of_results[True] = 0
                if False not in count_of_results.columns:
                    count_of_results[False] = 0

                # Calculate total and success ratio
                count_of_results['total'] = (
                    count_of_results[True]
                    + count_of_results[False]
                )
                count_of_results['success_ratio'] = (
                    count_of_results[True] / count_of_results['total']
                ) * 100

                # Display the diagnostics to ensure data is correct
                st.write(
                    "Diagnostics: After grouping and calculating "
                    "success ratio"
                )
                st.write(count_of_results)

                # Creating a bar chart
                fig = px.bar(
                    count_of_results,
                    x='sample_title',
                    y='success_ratio',
                    color='prompt_title',
                    title="Success Ratio by Sample Title and Prompt Title",
                    text='success_ratio'
                )
                fig.update_traces(
                    texttemplate='%{text:.2f}%',
                    textposition='outside'
                )
                fig.update_layout(
                    xaxis_title='Sample Title',
                    yaxis_title='Success Ratio (%)'
                )
                st.plotly_chart(fig)

            # Display title and data table in the main area
            st.title('Experiment Data Viewer')

            filtered_data = filtered_data[[
                'result_id', 'result','sample_title', 'prompt_title',
                'result_status','justification','key_stage_slug',
                'subject_slug','lesson_plan_id', 'run_date','prompt_lp_params'
            ]]
            st.dataframe(filtered_data)

        else:
            st.write("Please select an experiment to see more options.")
